{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uid: u1428543\n",
    "- Date: Jun 2, 2023\n",
    "- Class: CS6017\n",
    "\n",
    "# Homework 3 - Scraping and Regression\n",
    "\n",
    "## Part 1 - Data Acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from math import floor\n",
    "\n",
    "\n",
    "def calculate_time_gap(timestamp_string):\n",
    "    timestamp = datetime.datetime.fromisoformat(timestamp_string)\n",
    "\n",
    "    # Greenwich mean time is 6 hours ahead of MST\n",
    "    adjusted_time = timestamp - datetime.timedelta(hours=6)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    time_gap = (current_time - adjusted_time).total_seconds() / 3600\n",
    "\n",
    "    return floor(time_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "hackernews_file = 'hackernews_stories.csv'\n",
    "\n",
    "\n",
    "\n",
    "def scrape_hackernews_stories():\n",
    "    stories_data = []\n",
    "\n",
    "    for page in range(1, 6): \n",
    "        url = f\"https://news.ycombinator.com/news?p={page}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        story_rows = soup.select(\".athing\")\n",
    "\n",
    "        for row in story_rows:\n",
    "            rank = row.find(class_=\"rank\").text.strip(\".\")\n",
    "            title = row.find(class_=\"titleline\").text\n",
    "\n",
    "            next_row = row.find_next_sibling(\"tr\")\n",
    "           \n",
    "            if next_row:\n",
    "                original_age_string = next_row.find(class_=\"age\")['title']\n",
    "                age = calculate_time_gap(original_age_string)\n",
    "                points = next_row.find(class_=\"score\").text.split()[\n",
    "                    0] if next_row.find(class_=\"score\") else \"0\"\n",
    "                comments = next_row.find(\"a\", href=lambda href: href and \"item?id\" in href).text.split()[\n",
    "                    0] if next_row.find(\"a\", href=lambda href: href and \"item?id\" in href) else \"0\"\n",
    "            else:\n",
    "                age = \"N/A\"\n",
    "                points = \"N/A\"\n",
    "                comments = \"N/A\"\n",
    "\n",
    "\n",
    "            stories_data.append({\n",
    "                \"Rank\": rank,\n",
    "                \"Title\": title,\n",
    "                \"Age(hours)\": age,\n",
    "                \"Points\": points,\n",
    "                \"Comments\": comments\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(stories_data)\n",
    "    df.to_csv(hackernews_file, index=False)\n",
    "    print(f\"Scraping completed. Data saved to {hackernews_file}.\")\n",
    "\n",
    "# uncomment the next line to get new data\n",
    "# scrape_hackernews_stories()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Regression\n",
    "\n",
    "### Model 1: Multilinear regression with Title length, Age, Points, Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv(hackernews_file)\n",
    "\n",
    "df['Title Length'] = df['Title'].apply(len)\n",
    "\n",
    "X = df[['Title Length', 'Age(hours)', 'Points', 'Comments']]\n",
    "y = df['Rank']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "linear_reg = sm.OLS(y, X)\n",
    "linear_reg_result = linear_reg.fit()\n",
    "\n",
    "y_pred = linear_reg_result.predict(X)\n",
    "\n",
    "print(linear_reg_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_regression_results(y_pred, y_test, plot_title):\n",
    "    plt.scatter(y_pred, y_test)\n",
    "    plt.plot(y_test, y_test, color='blue', linewidth=1)  \n",
    "    plt.xlabel('Predicted Rank')\n",
    "    plt.ylabel('Actual Rank')\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_regression_results(\n",
    "    y_pred, y, 'Model 1: Multilinear regression with Title length, Age, Points, Comments')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Polynomial regression with age, age^2, points, points^2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[['Age(hours)', 'Points']].copy()\n",
    "y = df['Rank']\n",
    "\n",
    "X['Points^2'] = X['Points'] ** 2\n",
    "X['Age(hours)^2'] = X['Age(hours)'] ** 2\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the polynomial regression model\n",
    "polynomial_reg = sm.OLS(y, X)\n",
    "polynomial_reg_result = polynomial_reg.fit()\n",
    "\n",
    "y_pred = polynomial_reg_result.predict(X)\n",
    "\n",
    "# Print the summary of the polynomial regression model\n",
    "print(polynomial_reg_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_results(\n",
    "    y_pred, y, 'Model 2: Polynomial regression with age, age^2, points, points^2')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Lasso regression with Title length, Age, Points and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X = df[['Title Length', 'Age(hours)', 'Points', 'Comments']]\n",
    "y = df['Rank']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "lasso_reg = sm.OLS(y, X)\n",
    "lasso_reg_result = lasso_reg.fit_regularized(\n",
    "    alpha=1, L1_wt=1) \n",
    "\n",
    "print(lasso_reg_result.params)\n",
    "\n",
    "# Calculate predictions\n",
    "y_pred = lasso_reg_result.predict(X)\n",
    "\n",
    "# Calculate mean squared error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "tss = ((y - y.mean()) ** 2).sum()\n",
    "rss = ((y - y_pred) ** 2).sum()\n",
    "r_squared = 1 - (rss / tss)\n",
    "print(\"R-squared:\", r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_results(\n",
    "    y_pred, y, 'Model 3: Lasso regression with Title length, Age, Points and Comments')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which model is the most useful?\n",
    "\n",
    "Based on the R^2 scores and coefficients, the ranking of the usefulness of the three models is as follows:\n",
    "\n",
    "1. Model 2 (R^2 = 0.433)\n",
    "2. Model 1 (R^2 = 0.324)\n",
    "3. Model 3 (R^2 = 0.316)\n",
    "\n",
    "Among the three models, Model 2 stands out as the most useful. It has the highest R^2 score, indicating a better fit to the data and a higher degree of explained variance. \n",
    "\n",
    "The coefficients in Model 2 are very interesting. \n",
    "\n",
    "The coefficient of Age(hours) is positive (3.4589), but that of Age(hours)^2 is negative (-0.0333). This means that as the Age(hours) increases, the decrease in Rank becomes more pronounced at a decreasing rate. In other words, older posts tend to have lower ranks, but the impact decreases as the Age(hours) increases further.\n",
    "\n",
    "The coefficient of Points is negative (-0.1032) but that of Points^2 is a nearly 0 positive one (5.396e-05). This means that as the Points increases, the rank also decreases. More upvotes means higher ranking. The positive coefficient of Points^2 indicates that there is an upward curving relationship between Points and Rank. However, the coefficient value is very small, indicating that the impact of the squared term is minimal compared to the linear term of Points.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there linear relationships between any of the variables? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "X = df[['Title Length', 'Age(hours)', 'Points', 'Comments']]\n",
    "\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "print(correlation_matrix)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the correlations between these variables are relatively weak, with most values close to zero. This suggests that there is no strong linear relationship between these variables. However, it's important to note that correlation measures linear relationships and may not capture complex dependencies or non-linear associations between the variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula:\n",
    "\n",
    "$Score = \\frac{Points - 1}{(Age(hours) + 2)^{1.8}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "first_page_threshold_rank = 30\n",
    "\n",
    "df['Front Page'] = np.where(df['Rank'] <= first_page_threshold_rank, 1, 0)\n",
    "\n",
    "df['Score'] = (df['Points'] - 1) / (df['Age(hours)'] + 2) ** 1.8\n",
    "\n",
    "# Sort DataFrame by 'Score' in descending order\n",
    "df = df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Initialize 'Predicted Front Page' column with 0 for all rows\n",
    "df['Predicted Front Page'] = 0\n",
    "\n",
    "# Assign 1 to top 30 rows\n",
    "df.loc[:first_page_threshold_rank - 1,\n",
    "       'Predicted Front Page'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = ['blue', 'red']\n",
    "front_page_colors = [colors[fp] for fp in df['Front Page']]\n",
    "\n",
    "plt.scatter(df['Rank'], df['Score'], c=front_page_colors)\n",
    "plt.axhline(y=df.iloc[first_page_threshold_rank - 1]\n",
    "            ['Score'], color='black')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Set the title with different font sizes\n",
    "plt.title('Rank vs Score\\n(Posts above the black line are predicted to be on the front page)',\n",
    "          fontsize=12)\n",
    "\n",
    "# Add legends\n",
    "plt.scatter([], [], color='red', label='On Front Page')\n",
    "plt.scatter([], [], color='blue', label='Not on Front Page')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[['Score']]\n",
    "y = df['Front Page']\n",
    "\n",
    "# Add constant term to X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform logistic regression\n",
    "logit_model = sm.Logit(y, X)\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "# Predict the probabilities\n",
    "y_pred_proba = logit_result.predict(X)\n",
    "\n",
    "# Find the x value when y >= 0.5\n",
    "x_half_upper = X[y_pred_proba >= 0.5]['Score'].min()\n",
    "\n",
    "# Find the x value when y <= 0.5\n",
    "x_half_lower = X[y_pred_proba <= 0.5]['Score'].max()\n",
    "\n",
    "x_half = (x_half_upper + x_half_lower)/2\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Adding a red line where x = half_x\n",
    "plt.axvline(x=x_half, color='red', label='50/50 line')\n",
    "\n",
    "# Plot the logistic regression curve\n",
    "plt.scatter(df['Score'], df['Front Page'], color='blue', label='Actual')\n",
    "plt.plot(df['Score'], y_pred_proba, color='black', label='Predicted')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Front Page')\n",
    "plt.title('On front page classification vs calculated results')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "print(logit_result.summary())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Significance of Predictor Variables: Both the constant (const) and the Score variable are statistically significant at a significance level of 0.05. This suggests that both variables have a significant impact on the likelihood of making the front page.\n",
    "\n",
    "2. Coefficient Interpretation: The coefficient for the Score variable is 0.3521. This positive coefficient indicates that a higher Score is associated with a higher likelihood of making the front page.\n",
    "\n",
    "3. Pseudo R-squared: The Pseudo R-squared value of 0.2347 suggests that the logistic regression model explains approximately 23.47% of the variability in making the front page. This indicates a relatively poor explanatory power.\n",
    "   \n",
    "4. The LLR p-value of 2.919e-09 suggests that the logistic regression model as a whole is statistically significant in predicting the likelihood of making the front page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What do the regressions tell you about making the front page?\n",
    "\n",
    "Posts with more engagement from the community, as reflected by comments and points, have a higher chance of making it to the front page.\n",
    "\n",
    "Also, newer posts and posts with concise titles tend to have a better chance of reaching the front page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
