{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uid: u1428543\n",
    "- Date: May 17, 2023\n",
    "- Class: CS6017\n",
    "- HW 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Python/Numpy Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of 100 random numbers using the Numpy rand function.\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "current_time = int(time.time())\n",
    "np.random.seed(current_time)\n",
    "\n",
    "random_array_100 = np.random.rand(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compute the mean\n",
    "\n",
    "\n",
    "def calculate_mean(data):\n",
    "    return np.sum(data) / len(data)\n",
    "\n",
    "random_array_100_mean = calculate_mean(random_array_100)\n",
    "print(\"random_array_100_mean:\", random_array_100_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compute the standard deviation\n",
    "\n",
    "def calculate_std_deviation(data):\n",
    "    mean = calculate_mean(data)\n",
    "    squared_diff = np.power(data - mean, 2)\n",
    "    variance = np.sum(squared_diff) / (len(data) - 1)\n",
    "    std_deviation = np.sqrt(variance)\n",
    "    return std_deviation\n",
    "\n",
    "\n",
    "random_array_100_std_deviation = calculate_std_deviation(random_array_100)\n",
    "\n",
    "print(\"random_array_100_std_deviation:\", random_array_100_std_deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that your mean/std deviation functions work correctly. \n",
    "\n",
    "built_in_random_array_100_mean = np.mean(random_array_100)\n",
    "\n",
    "assert built_in_random_array_100_mean == random_array_100_mean, \"random_array_100_mean calculation is incorrect.\"\n",
    "\n",
    "built_in_random_array_100_std_deviation = np.std(random_array_100, ddof=1)\n",
    "\n",
    "assert built_in_random_array_100_std_deviation == random_array_100_std_deviation, \"random_array_100_std_deviation calculation is incorrect.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens (to the mean/std dev) when you increase the number of random numbers from 100 to 100000?\n",
    "\n",
    "random_array_100000 = np.random.rand(100000)\n",
    "\n",
    "random_array_100000_mean = calculate_mean(random_array_100000)\n",
    "\n",
    "random_array_100000_std_deviation = calculate_std_deviation(random_array_100000)\n",
    "\n",
    "print(\"random_array_100_mean:\", random_array_100_mean)\n",
    "\n",
    "print(\"random_array_100000_mean:\", random_array_100000_mean)\n",
    "\n",
    "if abs(random_array_100000_mean - 0.5) < abs(random_array_100_mean - 0.5):\n",
    "    print(\"The mean of random_array_100000 is closer to 0.5 than the mean of random_array_100, as expected.\")\n",
    "else:\n",
    "    print(\"The mean of random_array_100 is closer to 0.5 than the mean of random_array_100000.\")\n",
    "\n",
    "print(\"random_array_100_std_deviation:\", random_array_100_std_deviation)\n",
    "\n",
    "print(\"random_array_100000_std_deviation:\", random_array_100000_std_deviation)\n",
    "\n",
    "if random_array_100000_std_deviation < random_array_100_std_deviation:\n",
    "    print(\"The standard deviation of random_array_100000 is lower than the standard deviation of random_array_100.\")\n",
    "else:\n",
    "    print(\"The standard deviation of random_array_100 is lower than the standard deviation of random_array_100000.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use scipy.stats.norm to sample from the normal (gaussian) distribution to create an array of data (10000 values). \n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "norm_data_array_10000 = norm.rvs(size=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute the mean, and standard deviation of your set of samples using your functions, and with the built in numpy methods.\n",
    "\n",
    "norm_data_array_10000_mean = calculate_mean(norm_data_array_10000)\n",
    "\n",
    "norm_data_array_10000_std_deviation = calculate_std_deviation(norm_data_array_10000)\n",
    "\n",
    "built_in_norm_data_array_10000_mean = np.mean(norm_data_array_10000)\n",
    "\n",
    "built_in_norm_data_array_10000_std_deviation = np.std(norm_data_array_10000, ddof=1)\n",
    "\n",
    "assert built_in_norm_data_array_10000_mean == norm_data_array_10000_mean, \"norm_data_array_10000_mean calculation is incorrect.\"\n",
    "\n",
    "assert built_in_norm_data_array_10000_std_deviation == norm_data_array_10000_std_deviation, \"norm_data_array_10000_std_deviation calculation is incorrect.\"\n",
    "\n",
    "print(\"norm_data_array_10000_mean:\", norm_data_array_10000_mean)\n",
    "\n",
    "print(\"norm_data_array_10000_std_deviation:\", norm_data_array_10000_std_deviation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **What does the results of the mean/std dev of this data tell you about Scipy's norm's rvs function?**\n",
    "\n",
    "> The default behavior of Scipy's norm's rvs function is to generate data with a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of your samples (using the pyplot hist function). Experiment with using 10, 20, 40 bins.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_histogram(data, num_bins, ax):\n",
    "    ax.hist(data, bins=num_bins)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Histogram with {num_bins} bins for norm_data_array_10000')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "plot_histogram(norm_data_array_10000, num_bins=10, ax=axes[0])\n",
    "\n",
    "plot_histogram(norm_data_array_10000, num_bins=20, ax=axes[1])\n",
    "\n",
    "plot_histogram(norm_data_array_10000, num_bins=40, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Exploration/Analysis\n",
    "\n",
    "## Plot the readings over the course of a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SLC_PM2_5_SLC.csv')\n",
    "\n",
    "df = df.dropna(subset=['HW-MC'])\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(20, 6))  \n",
    "\n",
    "df['HW-MC'].plot()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM 2.5 Level')\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.title('Salt Lake City 2021 PM 2.5 Data Per Hour')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the mean PM2.5 level for each month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean = df['HW-MC'].resample('M').mean()\n",
    "\n",
    "# Convert the index to month names\n",
    "monthly_mean.index = monthly_mean.index.strftime('%B')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "monthly_mean.plot(kind='bar')\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Mean PM 2.5 Level')\n",
    "plt.title('Salt Lake City 2021 Mean PM 2.5 Level per Month')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Seasonal Variation: The PM 2.5 levels in Salt Lake City show a clear seasonal pattern. The levels are relatively lower in the early months of the year (January to April) with averages ranging from 4.7 to 8.7. Then, the levels gradually increase from May to August, reaching their peak in August with an average of 23.95. After August, the levels start to decrease again, remaining relatively elevated in September and October, and then gradually decreasing in November and December.\n",
    "2. Summer Pollution: The highest PM 2.5 level occurs in August, suggesting a potential influence of summer-related pollution sources. Factors such as wildfires, increased energy consumption (air condition, etc.), and atmospheric conditions during the summer months can contribute to higher pollution levels.\n",
    "3. Winter Inversion Effect: The relatively higher PM 2.5 levels in the winter months (January to March) could be attributed to the winter inversion effect. Utah’s winter inversions are a combination of several factors. Under normal conditions, air temperatures decrease with altitude. In the winter, when the ground is covered in snow that reflects heat, nights are longer, and the sun is supplying less warmth to the earth, temperatures can “invert” with warmer air on top of cooler air. When inverted temperatures combine with calm winds that reduce the natural mixing of cold and warm air, it creates a warm air “lid” that traps pollutants in Utah’s valleys, causing an inversion. ( reference: https://deq.utah.gov/communication/news/frequently-asked-questions-about-utahs-inversion-season )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the mean pollution level for each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_mean = df.groupby(df.index.hour)['HW-MC'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "hourly_mean.plot(kind='bar')\n",
    "\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Mean PM 2.5 Level')\n",
    "plt.title('Salt Lake City 2021 Mean PM 2.5 Level per Hour')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Morning traffic hypothesis: The highest average PM 2.5 level occurs around 10:00 AM with a value of 10.538 µg/m³. The peak at 10 PM could potentially be related to morning traffic. Salt Lake City may experience increased vehicle emissions during rush hour, which typically occurs in the morning. These emissions could contribute to higher PM 2.5 levels during that time, resulting in the observed peak.\n",
    "2. Evening activities and residential sources: The another peak at 8 PM could be attributed to various evening activities and residential sources ( including rush hour traffic ). During this time, people might be cooking dinner, using fireplaces or wood-burning stoves, or engaging in other activities that can release particulate matter into the air."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plot by month\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_grouped = df.groupby(df.index.month)\n",
    "\n",
    "boxplot_data = []\n",
    "\n",
    "for month, group_data in monthly_grouped:\n",
    "    boxplot_data.append(group_data['HW-MC'].values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(boxplot_data, labels=[\n",
    "            'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('PM2.5 Levels')\n",
    "plt.title('Salt Lake City 2021 Monthly PM2.5 Levels Per Month')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The presence of a long whisker and several outliers in August indicates that extreme values, possibly driven by factors such as wildfires, have a significant impact on the mean PM 2.5 level for that month. This emphasizes the importance of considering outliers and extreme values when interpreting the mean.\n",
    "2. November exhibits a lower mean compared to December, despite having a higher median. This indicates the influence of outliers in December, pulling the mean higher. These observations demonstrate that the mean can be less dependable in the presence of skewed distributions or outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plot by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_grouped = df.groupby(df.index.hour)\n",
    "\n",
    "boxplot_data = []\n",
    "\n",
    "for hour, group_data in hour_grouped:\n",
    "    boxplot_data.append(group_data['HW-MC'].values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(boxplot_data, labels=range(24))\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('PM2.5 Levels')\n",
    "plt.title('Salt Lake City 2021 Monthly PM2.5 Levels Per Hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Smooth Median and Percentiles: The smooth change in the median and percentiles throughout the day indicates a consistent pattern or trend in the PM 2.5 levels over the course of 24 hours. This smoothness suggests that there is generally a predictable variation in air quality throughout the day, with relatively consistent median and percentile values. This reflects the general trend and consistency in PM 2.5 levels throughout the day.\n",
    "2. Outliers Concentrated in a Range: Every hour exhibits a significant number of outliers, indicating the presence of extreme PM 2.5 values. These outliers tend to concentrate in a range from 20 to 60, suggesting a common range of higher pollution levels during most hours. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
